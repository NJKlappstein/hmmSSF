---
title: "State-switching step selection functions in hmmSSF"
author: "Natasha Klappstein & Th√©o Michelot"
date: "`r Sys.Date()`"
output:
  pdf_document:
    number_sections: yes
    citation_package: natbib
  html_document:
    df_print: paged
header-includes: \renewcommand{\baselinestretch}{1.2}
fontsize: 12pt
bibliography: refs.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE, error = FALSE, warning = FALSE,
  comment = NA
)
set.seed(4258)
```

\tableofcontents

\newpage
We describe the analysis workflow for the R package hmmSSF, which implements state-switching step selection functions as described by @klappstein2023 (and originally proposed by @nicosia2017). This package can be used to estimate behaviour-dependent habitat selection and movement parameters, bringing together hidden Markov models (@michelot2016) and step selection functions (@signer2019).

# Word of caution

This model is fairly complex compared to standard step selection functions, and requires more care to avoid numerical problems. Indeed, the number of parameters is higher, and the problem of inference requires estimating the dynamics of an unobserved state process (used as proxy for the behavioural state of the animal). 

In our experience, this model complexity often leads to numerical instability, i.e., failure of the fitting function to converge to the best parameter estimates. This is a difficult general problem, and here are some possible directions to explore to help with it:

- increase the number of control locations (see "Generating control step" below)

- use a simpler model formulation. The more complex the model, the more difficult it is to fit. It is usually good to start from the simplest model, i.e., a 2-state model with no covariates on the transition probabilities, and build up complexity if it seems possible.

- try different sets of starting values for the parameters (see "Starting parameter values" below)

# Data preparation

We consider an example (simulated) track with 2500 locations from one animal, and one spatial covariate. The tracking data is shown on top of a heatmap of the covariate in Figure \@ref(fig:plot-data).

```{r plot-data, echo = FALSE, fig.cap = "Example data.", fig.width = 6, fig.height = 5, out.width="60%", fig.align = "center"}
library(raster)
library(hmmSSF)
library(terra)
library(ggplot2)
theme_set(theme_bw())

# transform from raster to terra format
cov1 <- rast(cov1)

xyz <- as.data.frame(cbind(crds(cov1), values(cov1)))

ggplot(xyz, aes(x, y)) +
  geom_raster(aes(fill = layer)) +
  coord_equal() +
  scale_fill_gradientn(colours = c("royalblue", "white", "firebrick"),
                       name = NULL) +
  scale_x_continuous(limits = range(track$x) + c(-40, 40), expand = c(0, 0)) +
  scale_y_continuous(limits = range(track$y) + c(-5, 5), expand = c(0, 0)) +
  geom_path(data = track) +
  geom_point(data = track, size = 0.3)
```

## Format of tracking data

The package expects data to be provided as a data frame with the following columns:

- \texttt{ID}: identifier for track/animal

- \texttt{x}: Easting

- \texttt{y}: Northing

- \texttt{time}: time of observation

The locations need to be projected from longitude-latitude to Easting-Northing prior to analysis, as the package uses Euclidean (planar) geometry to derive metrics such as step lengths and turning angles.

```{r data}
head(track)
```

## Generating control steps

The most common method to fit a step selection function is to generate a set of "control" steps for each observed step, to weigh the suitability of the chosen move against alternatives. @forester2009 pointed out that it is advantageous to generate the control steps from distributions of movement variables that resemble the observed movement pattern. @klappstein2023 describe this as a form of importance sampling. 

In hmmSSF, the control steps are generated using the function \texttt{get\_controls()}, with multiple possible distributions (estimated from the observed data). The sampling distributions are specified by the argument \texttt{distr}, with the following options:

- if \texttt{distr = "uniform"}, then the control steps are generated by sampling points uniformly on a disc around each observed location, with radius set to the maximum observed step length. 

- if \texttt{distr} is set to \texttt{"gamma"} or \texttt{"exp"}, then this is used as a distribution of distances (estimated from the distribution of observed step lengths) to generate control steps, and the turning angles are uniform.

- if \texttt{distr} is specified as a vector of two character strings, then the first is used as distribution of distances (\texttt{"gamma"} or \texttt{"exp"}), and the second as a distribution of turning angles (\texttt{"vm"} or \texttt{"wrpcauchy"}) to generate control steps.

The number of control steps also needs to be specified, with larger numbers leading to better approximations but higher computational cost. In general, the choice of the distribution and number of control locations is difficult, as it can affect the results, but there is no general guidance. We encourage users to test different distributions and numbers of control locations, to assess the sensitivity of their inferences.

For this example, we decide to generate 50 control locations per observed step, using a gamma distribution of distances. The output has the same columns as the original data frame, and a few new ones: \texttt{stratum} identifies the stratum to which a location belongs, and \texttt{obs} is a binary variable indicating whether a location is observed or not.

```{r get-controls}
data <- get_controls(obs = track, n_controls = 50, distr = "gamma")

head(data)
```

In the importance sampling approach, the control steps need to be weighted during model fitting based on how likely they were under the distribution used to generate them. This technical detail is hidden in hmmSSF, and the weights are automatically computed and stored as an attribute of the data frame (for later use in \texttt{fitHMMSSF()}). For this reason, the control steps need to have been generated by \texttt{get\_controls()}, rather than some other method (e.g., the amt package). 

## Extracting spatial covariates

The spatial covariate needs to be evaluated at all observed and control locations. The raster is stored as a \texttt{SpatRaster}, and we use the package terra for this purpose.

```{r extract-covs}
data$cov1 <- extract(cov1, data[,c("x", "y")])$layer
```

# Model specification and model fitting

## Model formulation

The main modelling decisions are the choice of the number of states in the HMM, and the choice of the SSF formula within each state. 

There is no general method to select the best number of states, and we recommend leaning towards fewer states (2 or 3) in most applications to avoid numerical problems. (See also @pohle2017 for a discussion of this issue.) Here, we use two states, which we hope can separate slow and fast movement phases.

The formula should include movement variables as well as covariates (@avgar2016). For example, including step length (and possibly its log) captures the preference for some range of movement speeds, and including the cosine of turning angle captures directional persistence. See @avgar2016 and @klappstein2023 for more details. We use a formula with step length, log step length, cosine of turning angle, and the spatial covariate \texttt{cov1}.

```{r mod-def}
# number of HMM states
n_states <- 2

# SSF formula
ssf_formula <- ~ step + log(step) + cos(angle) + cov1
```

## Starting parameter values

In hmmSSF, the model is fitted through numerical likelihood optimisation, and starting values need to be chosen for the model parameters. The choice of these values does not affect the model specification, but poorly chosen values can lead to numerical problems (e.g., failure of optimiser to converge). The general idea is that, if starting values are close to the "true" parameters, it will be easier for the optimiser to converge. In practice, the true parameters are not known, and so our best bet is to choose plausible values given the data. 

Here, we use the fact that the selection parameters for \texttt{step} and \texttt{log(step)} are linked to the mean $\mu_L$ and standard deviation $\sigma_L$ of a gamma distribution through the relationships:
$$
  \beta_L = - \frac{\mu_L}{\sigma_L^2}, \quad \beta_{\log(L)} = \frac{\mu_L^2}{\sigma_L^2} - 2.
$$
We can choose some hypothesised mean step length for each state by looking at the empirical distribution, and transform them using these formulas to get starting values for the selection coefficients. To visualise step lengths, we subset the data to observed steps (i.e., removing control steps).

```{r plot-step, fig.width = 5, fig.height = 3, out.width="60%", fig.align = "center"}
ggplot(subset(data, obs == 1), aes(x = step)) +
  geom_histogram(col = "white", fill = "grey", bins = 20)
```

We might want state 1 to capture slow movement (e.g., steps between 0 and 1km), and state 2 to capture faster movement (e.g., steps between 1 and 3km), so we choose a mean of 0.2km for state 1 and 2km for state 2. We use the same value as the mean for the standard deviation in each state. Plugging these values into the above equations yields (-5, -0.5) for $\beta_L$, and (-1, -1) for $\beta_{\log(L)}$.

Similarly, the selection parameter for \texttt{cos(angle)} is the concentration of a von Mises distribution (@klappstein2023). The larger the concentration, the more peaked the distribution is around zero, i.e., the more directed the movement. We choose a starting value of 0.2 in state 1 and 5 in state 2, based on the expectation that slow movement is less directional than fast movement.

The parameters should be passed as a matrix, with one row for each covariate in the formula (here, 4), and one column for each state (here, 2).

```{r init-par}
# initial values for SSF parameters
ssf_par0 <- matrix(c(-5, -0.5,
                     -1, -1,
                     0.2, 5,
                     3, -1),
                   ncol = 2, byrow = TRUE)
```

## Model fitting

Finally, we can pass the model formulation, the data, and the starting parameter values to the function \texttt{fitHMMSSF()} for model fitting.

```{r mod-fit}
# fit model
mod <- hmmSSF(ssf_formula = ssf_formula,
              n_states = n_states,
              data = data,
              ssf_par0 = ssf_par0)
```

The fitted model object can then be printed to find the estimated parameter values.

```{r mod-print}
mod
```

# Interpretation of results

The function \texttt{plot\_ssf()} can be used to plot the step selection function against any covariate included in the model. \textbf{Important:} the y axis shows relative likelihoods of selection, and y values should only be interpreted by comparing two covariate values. More precisely, for some covariate $x$ (chosen as \texttt{var} argument) with estimated selection parameter $\beta$, the plot shows $k \times \exp(\beta x)$ against a grid of $x$ values. The multiplicative constant $k$ is arbitrary, which is why the scale of the y axis should only be interpreted in a relative way.

We first plot selection for step length $L$, $\exp(\beta_1 L + \beta_2 \log(L))$, in each state. The two distributions of step length are very different: state 1 captures shorter steps, and state 2 longer steps.
```{r plot-step, fig.width = 6, fig.height = 3, out.width="90%", fig.align = "center"}
plot_ssf(mod = mod, var = "step")
```

Similarly, we can plot selection for turning angle $\alpha$, i.e, $\exp(\beta_3 \cos(\alpha))$. Movement in both state tends to be directed (i.e., with a peak at zero), and the directionality is stronger in state 2. This is consistent with the expectation that fast movement also tends to be more directed.
```{r plot-angle, fig.width = 6, fig.height = 3, out.width="90%", fig.align = "center"}
plot_ssf(mod = mod, var = "angle")
```

Finally, we plot the selection for the spatial covariate \texttt{cov1}, i.e., $\exp(\beta_4 x)$. The results suggest that the animal selected for the covariate in state 1 (positive relationship), but tended to avoid it in state 2 (negative relationship).
```{r plot-cov1, fig.width = 6, fig.height = 3, out.width="90%", fig.align = "center"}
plot_ssf(mod = mod, var = "cov1")
```

Another useful output is the most likely state sequence, which can be computed with the function \texttt{viterbi\_decoding()}. We can use it to visualise the movement track coloured by states, which confirms that states 1 and 2 correspond to slow and fast movement, respectively.

```{r vit, fig.width = 4, fig.height = 5, out.width="50%", fig.align = "center"}
# get most likely state sequence
states <- viterbi_decoding(mod = mod)

# data frame for plotting (remove first two obs - not used in model)
df <- data.frame(x = track$x[-(1:2)], 
                 y = track$y[-(1:2)], 
                 state = factor(states))

ggplot(df, aes(x, y, col = state, group = NA)) +
  geom_path() +
  geom_point(size = 0.2) +
  coord_equal()
```

# Covariates on transition probabilities

The effects of covariates on the transition probabilities of the hidden process can be included with the argument \texttt{tpm\_formula}. @klappstein2023 describes this model, and discusses when a variable should be included in this part of the model (rather than in the SSF directly, say). Briefly, this option is useful to answer questions such as "Does this covariate affect the proportion of time spent in the different behaviours?". 

We add a column \texttt{tod} to the data frame, which is a numeric variable for the time of day. To include its effect on the transition probabilities, we define a formula with cyclical effects (with period = 24), based on trigonometric functions (@leos).

```{r mod-tpm}
data$tod <- lubridate::hour(data$time) + lubridate::minute(data$time) / 60

tpm_formula <- ~ cos(2 * pi * tod / 24) + sin(2 * pi * tod / 24)

mod2 <- hmmSSF(ssf_formula = ssf_formula, 
               tpm_formula = tpm_formula, 
               n_states = 2, 
               data = data, 
               ssf_par0 = ssf_par0)

mod2

new_data <- data.frame(tod = seq(0, 24, length = 100))
tpm <- predict_tpm(mod = mod2, new_data = new_data)
```

# References
